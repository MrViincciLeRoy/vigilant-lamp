name: Generate Horror Series and Send to Telegram

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]
  schedule:
    - cron: '0 0 * * 0' # Run weekly on Sunday at midnight UTC
  workflow_dispatch: # Allow manual triggering

jobs:
  generate-and-send:
    runs-on: ubuntu-latest

    steps:
      # Checkout the repository
      - name: Checkout code
        uses: actions/checkout@v4

      # Set up Python
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      # Install system dependencies
      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y espeak-ng libsndfile1

      # Install Python dependencies
      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install torch transformers llama-cpp-python huggingface_hub kokoro soundfile requests

      # Create directory for outputs
      - name: Create output directory
        run: mkdir -p outputs

      # Save the Python script
      - name: Save horror generator script
        run: |
          cat << 'EOF' > horror_generator.py
          # -*- coding: utf-8 -*-
          """Optimized Horror Episode Generator - Multi-Chapter Series"""
          import os
          import torch
          from huggingface_hub import hf_hub_download
          from llama_cpp import Llama
          from typing import Dict, List
          import gc
          import uuid
          import kokoro
          import soundfile as sf
          import numpy as np
          import requests
          import os

          class OptimizedHorrorGenerator:
              def __init__(self):
                  self.llm = None
                  self.model_loaded = False

              def load_model_optimized(self):
                  """Load model with CPU optimization"""
                  if self.model_loaded:
                      return

                  print("Loading model with CPU optimization...")
                  model_repo = "TheBloke/Llama-2-7B-Chat-GGUF"
                  model_filename = "llama-2-7b-chat.Q2_K.gguf"
                  model_path = hf_hub_download(repo_id=model_repo, filename=model_filename)

                  self.llm = Llama(
                      model_path=model_path,
                      n_gpu_layers=0,  # CPU only
                      n_ctx=4096,
                      n_batch=512,
                      n_threads=4,
                      f16_kv=True,
                      use_mmap=True,
                      use_mlock=False,
                      verbose=False
                  )
                  self.model_loaded = True
                  print("Model loaded successfully!")

              def generate_chapter(self, episode_data: Dict[str, str], chapter_num: int, prev_context: str,
                                  max_tokens: int = 600, temperature: float = 0.75, top_p: float = 0.9,
                                  repeat_penalty: float = 1.05) -> str:
                  """Generate a single chapter"""
                  if not self.model_loaded:
                      self.load_model_optimized()

                  if chapter_num == 1:
                      segment_prompt = f"""# Chapter {chapter_num}: Opening of '{episode_data['title']}'

Write the opening chapter of '{episode_data['title']}' in Jack Ketchum's horror style. Focus on psychological terror, vivid imagery, and a disturbing atmosphere. Introduce key characters and the setting based on the outline:

{episode_data['outline']}

Begin with a chilling atmosphere and character introductions, setting the stage for the horror to unfold:
"""
                  else:
                      segment_prompt = f"""# Chapter {chapter_num}: Continuation of '{episode_data['title']}'

Continue '{episode_data['title']}' in Jack Ketchum's horror style. Focus on escalating psychological terror, vivid imagery, and a disturbing atmosphere. Build on the previous chapter:

Previous: ...{prev_context[-200:]}

Advance the plot with new developments, intensifying the horror, and maintain narrative continuity:
"""

                  print(f"Generating Chapter {chapter_num}...")
                  output = self.llm(
                      segment_prompt,
                      max_tokens=max_tokens,
                      temperature=temperature,
                      top_p=top_p,
                      repeat_penalty=repeat_penalty,
                      stop=["###", "---"],
                      echo=False
                  )
                  return output['choices'][0]['text'].strip()

              def generate_series(self, episode_data: Dict[str, str], num_chapters: int = 5,
                                 tokens_per_chapter: int = 600) -> Dict[str, str]:
                  """Generate a multi-chapter horror series"""
                  if not self.model_loaded:
                      self.load_model_optimized()

                  chapters = []
                  prev_context = ""

                  for chapter_num in range(1, num_chapters + 1):
                      chapter_text = self.generate_chapter(episode_data, chapter_num, prev_context,
                                                          max_tokens=tokens_per_chapter)
                      chapters.append(f"# Chapter {chapter_num}\n\n{chapter_text}")
                      prev_context = chapter_text
                      gc.collect()

                  full_text = "\n\n".join(chapters)
                  word_count = len(full_text.split())
                  print(f"Generated series with {word_count} words across {num_chapters} chapters")
                  return {'title': episode_data['title'], 'text': full_text}

          def read_markdown_file(file_path: str) -> str:
              """Reads markdown file content"""
              with open(file_path, 'r', encoding='utf-8') as f:
                  return f.read()

          def extract_episode_outline(markdown_text: str) -> Dict[str, str]:
              """Extract episode data from markdown"""
              lines = markdown_text.split('\n')
              episode_title = ""
              for line in lines:
                  if line.startswith('# ') and not episode_title:
                      episode_title = line[2:].strip()
                      break
              return {'title': episode_title or 'Untitled Episode', 'outline': markdown_text.strip()}

          def save_episode(episode: Dict[str, str], filename: str = 'outputs/blood_pact_series.md'):
              """Save episode series to file"""
              with open(filename, 'w', encoding='utf-8') as f:
                  f.write(f"# {episode['title']}\n\n")
                  f.write(episode['text'])
                  f.write(f"\n\n---\n*Words: {len(episode['text'].split())}*\n")
              print(f"Series saved: {filename} ({len(episode['text'].split())} words)")

          def generate_audio(text: str, output_file: str = 'outputs/complete_narration.wav'):
              """Generate audio narration"""
              pipeline = kokoro.KPipeline(lang_code='a')
              audio_segments = []
              generator = pipeline(text, voice='bm_fable')

              for i, (gs, ps, audio) in enumerate(generator):
                  print(f"Processing audio segment {i}: {gs} -> {ps}")
                  audio_segments.append(audio)

              if audio_segments:
                  combined_audio = np.concatenate(audio_segments, axis=0)
                  sf.write(output_file, combined_audio, 24000)
                  print(f"Complete narration saved as '{output_file}'")
                  print(f"Total duration: {len(combined_audio) / 24000:.2f} seconds")
                  return output_file
              else:
                  print("No audio segments generated")
                  return None

          def send_to_telegram(bot_token: str, chat_id: str, text_file: str, audio_file: str):
              """Send files to Telegram bot"""
              url = f"https://api.telegram.org/bot{bot_token}/sendDocument"
              files = [
                  ('document', ('blood_pact_series.md', open(text_file, 'rb'))),
                  ('document', ('complete_narration.wav', open(audio_file, 'rb')))
              ]
              for file_name, file_data in files:
                  data = {'chat_id': chat_id}
                  response = requests.post(url, data=data, files={'document': file_data})
                  if response.status_code == 200:
                      print(f"Successfully sent {file_name} to Telegram")
                  else:
                      print(f"Failed to send {file_name}: {response.text}")

          def main():
              # Create episode outline
              outline_content = """# The Blood Pact
In October 2020, Sebenzile Maphanga was brutally murdered in a ritualistic killing orchestrated by her boyfriend, Collen Mathonsi, and a traditional healer (sangoma), Frans Nkuna. Mathonsi, seeking supernatural powers, was advised by Nkuna to sacrifice Maphanga. He lured her to Nkuna's premises, where she was rendered unconscious, bludgeoned to death with a hammer, and her blood drained into a bucket. Her body was then mutilated and disposed of in the Dubai informal settlement, north of Pretoria. Nkuna led police to the charred remains, and Mathonsi turned state witness, serving a 35-year sentence. Nkuna is currently on trial for murder and kidnapping.

The story closes as the boyfriend turns state witness, confessing everything. Meanwhile, the sangoma awaits trial but claims the ritual was meant for protection, not death. The investigators visit the site where her body was burned, feeling a chill and hearing whispers carried by the wind."""
              
              with open('fast_outline.md', 'w') as f:
                  f.write(outline_content)

              # Initialize generator
              generator = OptimizedHorrorGenerator()

              # Load episode data
              markdown_text = read_markdown_file('fast_outline.md')
              episode_data = extract_episode_outline(markdown_text)

              print("=== SERIES GENERATION ===")
              series = generator.generate_series(episode_data, num_chapters=5, tokens_per_chapter=600)
              save_episode(series)

              print("\n=== AUDIO GENERATION ===")
              audio_file = generate_audio(series['text'])

              print("\n=== SENDING TO TELEGRAM ===")
              bot_token = os.getenv('TELEGRAM_BOT_TOKEN')
              chat_id = os.getenv('TELEGRAM_CHAT_ID')
              if bot_token and chat_id and audio_file:
                  send_to_telegram(bot_token, chat_id, 'outputs/blood_pact_series.md', audio_file)
              else:
                  print("Telegram bot token or chat ID not set, or audio generation failed")

          if __name__ == "__main__":
              main()
          EOF

      # Run the horror generator script
      - name: Run horror generator
        env:
          TELEGRAM_BOT_TOKEN: ${{ secrets.TELEGRAM_BOT_TOKEN }}
          TELEGRAM_CHAT_ID: ${{ secrets.TELEGRAM_CHAT_ID }}
        run: python horror_generator.py

      # Upload artifacts
      - name: Upload story and audio
        uses: actions/upload-artifact@v4
        with:
          name: horror-series-outputs
          path: outputs/

      # Clean up
      - name: Clean up
        run: |
          rm -rf outputs
          rm -f fast_outline.md
          rm -f horror_generator.py
